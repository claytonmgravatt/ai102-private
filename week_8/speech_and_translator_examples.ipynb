{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech resource configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "speech_api_key = os.environ.get(\"AZURE_SPEECH_API_KEY\")\n",
    "speech_region = os.environ.get(\"AZURE_SPEECH_REGION\") #Note this takes a REGION instead of an endpoint!\n",
    "credential = AzureKeyCredential(speech_api_key)\n",
    "\n",
    "#Speech config is the speech RESOURCE config, used for both Text-To-Speech and Speech-To-Text\n",
    "speech_config = speechsdk.SpeechConfig(\n",
    "    subscription=speech_api_key, region=speech_region\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech-To-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Input Config is also the audio DEVICE config, used for Speech-To-Text\n",
    "audio_input_config = speechsdk.audio.AudioConfig(use_default_microphone=True) #Using microphone, but could be text file instead\n",
    "\n",
    "# Speech Recognizer is our \"client\" used for Speech-To-Text\n",
    "speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "    speech_config=speech_config, audio_config=audio_input_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code waits\n",
      "SpeechRecognitionResult(result_id=ab993028145c430d97abc26f8efd6bf3, text=\"Could waits for me to say something and it'll spit something out at the other end.\", reason=ResultReason.RecognizedSpeech)\n"
     ]
    }
   ],
   "source": [
    "#Synchronous (blocking) single recognition\n",
    "speech_result = speech_recognizer.recognize_once() # stops on silence or after 15 seconds\n",
    "\n",
    "print('Code waits...')\n",
    "\n",
    "print(speech_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code keeps going\n",
      "SpeechRecognitionResult(result_id=66bad5855cc24991ac8cfc459d171cf4, text=\"Or I can do it this way where it returns to future promise I guess.\", reason=ResultReason.RecognizedSpeech)\n"
     ]
    }
   ],
   "source": [
    "#Asynchronous (non-blocking) single recognition\n",
    "speech_recognition_result_future = speech_recognizer.recognize_once_async() # stops on silence or after 15 seconds\n",
    "\n",
    "print('Code keeps going')\n",
    "\n",
    "speech_recognition_result = speech_recognition_result_future.get()\n",
    "print(speech_recognition_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting continuous recognition...\n",
      "Session started.\n",
      "Recognizing: and\n",
      "Recognizing: and trying again\n",
      "Recognizing: and trying again this\n",
      "Recognizing: and trying again this way so it looks\n",
      "Recognizing: and trying again this way so it looks good that's\n",
      "Recognizing: and trying again this way so it looks good that's great\n",
      "Recognized: And trying again this way so it looks good. That's great.\n",
      "Stopping continuous recognition...\n",
      "Session stopped.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Continuous recognition. Requires connecting callsbacks for handling various events.\n",
    "\n",
    "# Note, this async method doesn't play nicely with my notebook, so I have to repeat the config setup within the same cell.\n",
    "speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "    speech_config=speech_config, audio_config=audio_input_config\n",
    ")\n",
    "\n",
    "#I'm just printing all events, but this could be much more complicated event handling.\n",
    "def on_recognizing(event):\n",
    "    print(f\"Recognizing: {event.result.text}\")\n",
    "\n",
    "def on_recognized(event):\n",
    "    print(f\"Recognized: {event.result.text}\")\n",
    "\n",
    "def on_canceled(event):\n",
    "    print(f\"Canceled: {event.reason}\")\n",
    "\n",
    "def on_session_started(event):\n",
    "    print(\"Session started.\")\n",
    "\n",
    "def on_session_stopped(event):\n",
    "    print(\"Session stopped.\")\n",
    "\n",
    "# Connect callbacks to the events fired by the speech recognizer\n",
    "speech_recognizer.recognizing.connect(on_recognizing)\n",
    "speech_recognizer.recognized.connect(on_recognized)\n",
    "speech_recognizer.canceled.connect(on_canceled)\n",
    "speech_recognizer.session_started.connect(on_session_started)\n",
    "speech_recognizer.session_stopped.connect(on_session_stopped)\n",
    "\n",
    "print(\"Starting continuous recognition...\")\n",
    "speech_recognizer.start_continuous_recognition_async()\n",
    "\n",
    "# Run for 10 seconds and then stop continuous recognition\n",
    "import time\n",
    "time.sleep(10)\n",
    "print(\"Stopping continuous recognition...\")\n",
    "speech_recognizer.stop_continuous_recognition_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-To-Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text-To-Speech\n",
    "\n",
    "# Audio Output Config is the audio DEVICE config, used for Text-To-Speech\n",
    "audio_output_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True) #Using speaker, but could be audio file instead\n",
    "\n",
    "# Speech Synthesizer is our \"client\" used for Text-To-Speech\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(\n",
    "    speech_config=speech_config, audio_config=audio_output_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code waits...\n"
     ]
    }
   ],
   "source": [
    "#Synchronous (blocking) single synthesis\n",
    "speech_synthesizer.speak_text(\"I am a friendly robot and I do not intend to take over the world.\")\n",
    "\n",
    "print('Code waits...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code continues...\n",
      "SpeechSynthesisResult(result_id=464d91f12ea44646a67b74046f459784, reason=ResultReason.SynthesizingAudioCompleted, audio_length=170046)\n"
     ]
    }
   ],
   "source": [
    "#Synchronous (blocking) single synthesis\n",
    "result_future = speech_synthesizer.speak_text_async(\"I am a friendly robot and I do not intend to take over the world.\")\n",
    "\n",
    "print('Code continues...')\n",
    "\n",
    "result = result_future.get()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.cognitiveservices.speech.ResultFuture at 0x2392e1c5b20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other async methods too..\n",
    "speech_synthesizer.start_speaking_text_async(\"one, two, three, four, five, six, seven, eight...\")\n",
    "\n",
    "import time\n",
    "time.sleep(3)\n",
    "\n",
    "speech_synthesizer.stop_speaking_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.cognitiveservices.speech.SpeechSynthesisResult at 0x20a1392e8e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change voice\n",
    "speech_config.speech_synthesis_voice_name = \"en-US-AshleyNeural\"\n",
    "\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(\n",
    "    speech_config=speech_config, audio_config=audio_output_config\n",
    ")\n",
    "speech_synthesizer.speak_text(\"I am a friendly robot and I do not intend to take over the world.\")\n",
    "\n",
    "\n",
    "# Change voice\n",
    "speech_config.speech_synthesis_voice_name = \"en-US-AIGenerate1Neural\"\n",
    "\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(\n",
    "    speech_config=speech_config, audio_config=audio_output_config\n",
    ")\n",
    "speech_synthesizer.speak_text(\"I am a friendly robot and I do not intend to take over the world.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.cognitiveservices.speech.SpeechSynthesisResult at 0x20a13caf970>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change voice\n",
    "speech_config.speech_synthesis_voice_name = \"en-US-NancyNeural\"\n",
    "\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(\n",
    "    speech_config=speech_config, audio_config=audio_output_config\n",
    ")\n",
    "speech_synthesizer.speak_text(\"I am a friendly robot and I do not intend to take over the world.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.cognitiveservices.speech.SpeechSynthesisResult at 0x20a13bfac10>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SSML to change pitch, speaking style, rate...\n",
    "ssml_text = \"\"\"\n",
    "<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts' xml:lang='en-US'>\n",
    "  <voice name='en-US-NancyNeural'>\n",
    "    <mstts:express-as style='unfriendly'>\n",
    "        <prosody pitch='+15Hz'>\n",
    "            Oh, I am such a friendly robot, and I\n",
    "            <mstts:express-as style='whispering' styledegree=\"2\">\n",
    "                <prosody pitch='+20Hz' rate='-20%'>\n",
    "                    definitely\n",
    "                </prosody>\n",
    "            </mstts:express-as>\n",
    "            don't want to take over the world!\n",
    "        </prosody>\n",
    "    </mstts:express-as>\n",
    "  </voice>\n",
    "</speak>\n",
    "\"\"\"\n",
    "speech_synthesizer.speak_ssml(ssml_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.cognitiveservices.speech.SpeechSynthesisResult at 0x20a13d696a0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SSML to change language.\n",
    "# Note multilingual voice name, and de-DE language tag\n",
    "ssml_text = \"\"\"\n",
    "<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"https://www.w3.org/2001/mstts\" xml:lang=\"en-US\">\n",
    "    <voice name=\"en-US-AvaMultilingualNeural\">\n",
    "        <lang xml:lang=\"de-DE\">\n",
    "            Ich bin ein freundlicher Roboter und habe nicht vor, die Welt zu erobern\n",
    "        </lang>\n",
    "    </voice>\n",
    "</speak>\n",
    "\"\"\"\n",
    "speech_synthesizer.speak_ssml(ssml_text)\n",
    "\n",
    "#Note en-US language tag\n",
    "ssml_text = \"\"\"\n",
    "<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"https://www.w3.org/2001/mstts\" xml:lang=\"en-US\">\n",
    "    <voice name=\"en-US-AvaMultilingualNeural\">\n",
    "        <lang xml:lang=\"en-US\">\n",
    "            Ich bin ein freundlicher Roboter und habe nicht vor, die Welt zu erobern.\n",
    "        </lang>\n",
    "    </voice>\n",
    "</speak>\n",
    "\"\"\"\n",
    "speech_synthesizer.speak_ssml(ssml_text)\n",
    "\n",
    "#Note de-DE voice\n",
    "ssml_text = \"\"\"\n",
    "<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"https://www.w3.org/2001/mstts\" xml:lang=\"en-US\">\n",
    "    <voice name=\"de-DE-TanjaNeural\">\n",
    "        <lang xml:lang=\"en-US\">\n",
    "            I am a friendly robot and I do not intend to take over the world.\n",
    "        </lang>\n",
    "    </voice>\n",
    "</speak>\n",
    "\"\"\"\n",
    "speech_synthesizer.speak_ssml(ssml_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speech translation config is the speech RESOURCE config\n",
    "speech_translation_config = speechsdk.translation.SpeechTranslationConfig(\n",
    "    subscription=speech_api_key, region=speech_region\n",
    ")\n",
    "\n",
    "# Note how the arguments are identical to the normal speech resource config\n",
    "#   speech_config = speechsdk.SpeechConfig(\n",
    "#       subscription=speech_api_key, region=speech_region\n",
    "#   )\n",
    "\n",
    "# However, it has some new methods\n",
    "speech_translation_config.speech_recognition_language=\"en-US\"\n",
    "speech_translation_config.add_target_language(\"fr\")\n",
    "speech_translation_config.add_target_language(\"de\")\n",
    "\n",
    "# Reusing our audio input config from earlier...\n",
    "audio_input_config = speechsdk.audio.AudioConfig(\n",
    "    use_default_microphone=True\n",
    ")\n",
    "\n",
    "# Recognizer client takes a translaction config and an audio config.\n",
    "translation_recognizer = speechsdk.translation.TranslationRecognizer(\n",
    "    translation_config=speech_translation_config, audio_config=audio_input_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TranslationRecognitionResult(result_id=e15af6e15cca4dbdb3db2ce37a5ca2b7, translations={'fr': 'Il s’agit de tester la traduction unique.', 'de': 'Dies ist das Testen der einzelnen Übersetzung.'}, reason=ResultReason.TranslatedSpeech)\n"
     ]
    }
   ],
   "source": [
    "#Single blocking translation recognition\n",
    "translation_result = translation_recognizer.recognize_once()\n",
    "print(translation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also has other methods you'd expect...\n",
    "translation_recognizer.recognize_once_async()\n",
    "translation_recognizer.start_continuous_recognition()\n",
    "translation_recognizer.stop_continuous_recognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr Je suis un robot amical et je ne veux pas conquérir le monde.\n",
      "de Ich bin ein freundlicher Roboter und möchte nicht die Weltherrschaft übernehmen.\n"
     ]
    }
   ],
   "source": [
    "# Speech to translated speech example\n",
    "translation_result = translation_recognizer.recognize_once()\n",
    "\n",
    "# Mapping voices to languages\n",
    "voices_lookup = {\n",
    "    \"de\": \"de-DE-KlarissaNeural\",\n",
    "    \"fr\": \"fr-FR-MauriceNeural\"\n",
    "}\n",
    "\n",
    "for language, translation in translation_result.translations.items():\n",
    "    print(language, translation)\n",
    "\n",
    "    #Set voice based on language to translate to.\n",
    "    voice_name = voices_lookup.get(language)\n",
    "    speech_config.speech_synthesis_voice_name = voice_name\n",
    "\n",
    "    #Construct synthesizer with correct voice.\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(\n",
    "        speech_config=speech_config, audio_config=audio_output_config\n",
    "    )\n",
    "    \n",
    "    #Speak.\n",
    "    speech_synthesizer.speak_text(translation)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Translator SDK is currently in beta, hopefully it's improved.\n",
    "from azure.ai.translation.text import TextTranslationClient, TranslatorCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "translator_api_key = os.environ.get(\"AZURE_TRANSLATOR_API_KEY\")\n",
    "translator_region = os.environ.get(\"AZURE_TRANSLATOR_REGION\") \n",
    "translator_endpoint = os.environ.get(\"AZURE_TRANSLATOR_ENDPOINT\")\n",
    "\n",
    "#Note this is NOT the default AzureKeyCredential and it takes a region AND an endpoint!\n",
    "credential = TranslatorCredential(translator_api_key, translator_region) \n",
    "text_translator = TextTranslationClient(endpoint=translator_endpoint, credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation Result:\n",
      "{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Ich bin ein freundlicher Roboter und habe nicht die Absicht, die Weltherrschaft zu übernehmen', 'to': 'de'}, {'text': 'Je suis un robot amical, et je n’ai pas l’intention de conquérir le monde', 'to': 'fr'}]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.translation.text.models import InputTextItem\n",
    "\n",
    "#Translation method takes an array of \"InputTextItem\" models\n",
    "translation_result = text_translator.translate(\n",
    "    content=[\n",
    "        InputTextItem(\n",
    "            text=\"I am a friendly robot, and I do not intend to take over the world\"\n",
    "        )\n",
    "    ],\n",
    "    to=[\"de\", \"fr\"],\n",
    ")[0]\n",
    "\n",
    "print('Translation Result:')\n",
    "print(translation_result, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transliterated text: 'Kon'nichiwa​'.\n"
     ]
    }
   ],
   "source": [
    "# Transliteration\n",
    "transliteration = text_translator.transliterate(\n",
    "    content=[InputTextItem(text=\"こんにちは\")],\n",
    "    language=\"ja\",\n",
    "    from_script=\"Jpan\",\n",
    "    to_script=\"Latn\",\n",
    ")[0]\n",
    "\n",
    "print(f\"Transliterated text: '{transliteration.text}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextTranslationClient' object has no attribute 'detect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#What? This isn't implemented?\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtext_translator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m() \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TextTranslationClient' object has no attribute 'detect'"
     ]
    }
   ],
   "source": [
    "# What? This isn't implemented?\n",
    "text_translator.detect() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-102-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
